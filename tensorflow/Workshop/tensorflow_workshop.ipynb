{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow hands-on!\n",
    "\n",
    "Hello and welcome to the hands-on portion of the **Image Recognition** workshop. By now, you should have a good understanding of how Convolutional Neural Networks work and what TensorFlow is. We'll now move to building an image recognition model. \n",
    "\n",
    "### The Case \n",
    "Today we will be working on a simple case - classifying images from the Nederlandse Vereniging Makelaars. The classes include binnen, buiten, and mappen. Like this: \n",
    "\n",
    "<img src='labels.jpg'>\n",
    "\n",
    "\n",
    "### Outline\n",
    "<img src='outline2.jpg' align=left>\n",
    "<br><br><br><br><br>\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Images\n",
    "\n",
    "The first thing that we need to do is to import and process our images. \n",
    "\n",
    "#### What does processing mean? \n",
    "When we need to build our computational graph, we have to define what the input data shape is. THis is a core component of TensorFlow - in that before you do anything, you define an abstract architecture for processing vectors (tensors). \n",
    "\n",
    "In our case, we are going to reshape our images to 256x256 pixels! \n",
    "\n",
    "Like this: \n",
    "<img src='compressed.jpg'>\n",
    "\n",
    "\n",
    "### Importing images \n",
    "Luckily, we can import the images from their .jpg format and convert them into a processed array with just a few lines of code. Let's move to the code to get an idea as to what we are doing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Packages \n",
    "\n",
    "Before we do anything in our script, let's import the packages we will be using throughout this hands-on excercise. To get an idea what these packages do, see this: \n",
    "\n",
    "<img src='packages2.jpg' align=left width=400 >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "########### Don't change this code ###############\n",
    "##################################################\n",
    "\n",
    "# For accessing files and storing information\n",
    "import numpy as np \n",
    "import glob\n",
    "\n",
    "# To mediate impatience\n",
    "import progressbar \n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "\n",
    "# For encoding labels \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For converting images to numeric values\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "# Some functions we'll need \n",
    "from tools import one_hot_encoder, batch_norm_layer, random_batch\n",
    "\n",
    "# For building our model \n",
    "import tensorflow as tf \n",
    "\n",
    "##################################################\n",
    "##################################################\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Images\n",
    "\n",
    "Let's get our images into our working directory! \n",
    "\n",
    "To do so, define some list objects that will contain the path to each image in your images directory. You can do this by calling:\n",
    "<br>\n",
    "```\n",
    "# Fill list with paths of images\n",
    "image_paths = glob.glob('path/to/images/*.jpg')\n",
    "\n",
    "```\n",
    "\n",
    "**Remember to do this for each class! **\n",
    "\n",
    "\n",
    "Next, we need to combine all of our lists with our class filepaths. You can do this by calling: \n",
    "<br>\n",
    "```\n",
    "# Combine lists of class file paths \n",
    "all_paths = np.concatenate([class1_paths, class2_paths, class3_paths])\n",
    "```\n",
    "\n",
    "<br>\n",
    "Then let's print the file paths! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images/binnen\\\\0000002.jpg' 'images/binnen\\\\0000003.jpg'\n",
      " 'images/binnen\\\\0000004.jpg' 'images/binnen\\\\0000005.jpg'\n",
      " 'images/binnen\\\\0000006.jpg']\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "################### Start Here ###################\n",
    "##################################################\n",
    "\n",
    "# Fill list with paths to photos \n",
    "binnen_paths = glob.glob('images/binnen/*.jpg')\n",
    "buiten_paths = glob.glob('images/buiten/*.jpg')\n",
    "mappen_paths = glob.glob('images/map/*.jpg')\n",
    "\n",
    "# Combine the data\n",
    "paths = np.concatenate([binnen_paths, buiten_paths, mappen_paths])\n",
    "\n",
    "# Print the first 5 values in the array paths\n",
    "print(paths[:5])\n",
    "\n",
    "\n",
    "##################################################\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the label set\n",
    "\n",
    "Well now that we have the paths to each class's images, it is quite easy to define the label set. We will do this by creating arrays with the class name, and filling it with that value for the number of iamges we have for that label. \n",
    "\n",
    "You can do this by calling: \n",
    "<br>\n",
    "```\n",
    "class_label = np.array(['class_name'] * len(class_paths))\n",
    "```\n",
    "\n",
    "<br> Let's try it out! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binnen' 'binnen' 'binnen' 'binnen' 'binnen']\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "################### Start Here ###################\n",
    "##################################################\n",
    "\n",
    "# Defining the label set \n",
    "binnen_label = np.array(['binnen'] * len(binnen_paths))\n",
    "buiten_label = np.array(['buiten'] * len(buiten_paths))\n",
    "mappen_label = np.array(['map'] * len(mappen_paths))\n",
    "\n",
    "# Combine the data\n",
    "labels = np.concatenate([binnen_label, buiten_label, mappen_label])\n",
    "\n",
    "# Print the first 5 labels (should all be binnen)\n",
    "print(labels[:5])\n",
    "\n",
    "\n",
    "##################################################\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import images as arrays \n",
    "\n",
    "This part is a little bit tricky. \n",
    "\n",
    "<br>What we are going to do is call the keras ```load_img``` and ```img_to_array``` functions. We want to store these as *unint8* data type in order to reduce memory usage. We'll append each array to a list, and then turn that list into an array - creating an array of arrays. This should become easier when we print out the shape of the array. \n",
    "\n",
    "<br>\n",
    "Our goal is to make images into something like this: \n",
    "<img src='img_to_array.jpg'>\n",
    "\n",
    "\n",
    "#### For loop\n",
    "<br> \n",
    "If you're familiar with programming fundamentals, you already know what a for loop is. In this example, we need to \"loop\" over each *path* in our list of filepaths, and turn that image into an array. An example of a simple for loop is as follows:\n",
    "<br>\n",
    "``` \n",
    "# Loop over all paths in list of file paths\n",
    "for path in paths:\n",
    "\n",
    "    # Load each specified image (from the file path)\n",
    "    image = load_img(path, target=(256, 256))\n",
    "    \n",
    "    # Conver the image into an array\n",
    "    image = img_to_array(image)\n",
    "    \n",
    "    # Append to a list\n",
    "    image_list.append(image)\n",
    "    \n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "Let's try this out! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "########### Don't change this code ###############\n",
    "##################################################\n",
    "\n",
    "# Initialize an empty list to fill with image arrays\n",
    "image_list = []\n",
    "\n",
    "# Initiate a progress bar\n",
    "bar = progressbar.ProgressBar(maxval=len(paths)).start()\n",
    "\n",
    "\n",
    "##################################################\n",
    "################### Start Here ###################\n",
    "##################################################\n",
    "\n",
    "\n",
    "# Loop through the directory and fill list with resized pixel values\n",
    "for index, path in enumerate(paths): \n",
    "    \n",
    "    # Resizes the image to 256x256x3 resolution\n",
    "    image = load_img(path, target_size=(256, 256, 3))\n",
    "    \n",
    "    # Converts the image object to an array (of type unint8 for efficient storage) \n",
    "    image = img_to_array(image).astype(np.uint8)\n",
    "    \n",
    "    # Append the array to the image list\n",
    "    image_list.append(image)\n",
    "    \n",
    "    # Update the progressbar\n",
    "    bar.update(index)\n",
    "    \n",
    "# Convert the image list to a numpy array \n",
    "image_array = np.array(image_list)\n",
    "\n",
    "print(image_array.shape)\n",
    "\n",
    "##################################################\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding\n",
    "<br>\n",
    "Right now, our labels object is an array with the labels *binnen*, *buiten*, and *map*. Unforunately, computers are not as smart as we are, and need these words to be represented as numbers in order to process them. \n",
    "\n",
    "One-hot encoding is the process of turning labels into a computer-readable format, and looks like this. \n",
    "<br>\n",
    "\n",
    "<img src='hot_encode.jpg'>\n",
    "\n",
    "<br>\n",
    "\n",
    "To hot encode, just call our ```one_hot_encoder``` function we imported from our tools library! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "################### Start Here ###################\n",
    "##################################################\n",
    "\n",
    "# Call one_hot_encoder() function on the labels!\n",
    "hot_encoded, label_classes = one_hot_encoder(labels)\n",
    "\n",
    "\n",
    "##################################################\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs, outputs, and train-test-split\n",
    "\n",
    "So now that we have our images and labels stored as numeric vectors - we can assign them to our input $X$ variable, and the labels as our $y$ variable. \n",
    "\n",
    "<br>\n",
    "$X = images$\n",
    "<br>\n",
    "$y = labels$\n",
    "<br>\n",
    "\n",
    "\n",
    "### Train test split \n",
    "\n",
    "#### Why do we perform a train/test split? \n",
    "The reason we perform a train/test split is to understand how well our model approximates on a general distribution of inputs. In other words, how do we know if our model will work, if we do not test it on data it has never seen before? \n",
    "<br>\n",
    "\n",
    "<img src='traintest.jpg'>\n",
    "\n",
    "<br>\n",
    "\n",
    "To perform a train test split on our dataset, call the ```train_test_split``` function, like this: \n",
    "<br>\n",
    "```\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "################### Start Here ###################\n",
    "##################################################\n",
    "\n",
    "# Define images as input X and labels as output y \n",
    "X = image_array \n",
    "y = hot_encoded\n",
    "\n",
    "# Perform a train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25)\n",
    "\n",
    "\n",
    "##################################################\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Useful Functions\n",
    "\n",
    "### Placeholders \n",
    "\n",
    "By now, you understand that tensorflow is an abstract computing language. For this reason - we create *placeholders* to feed data into later. This will contribute to our computational graph that we build later on. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_h0, n_w0, n_c0, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_h0 -- scalar, height of an input image\n",
    "    n_w0 -- scalar, width of an input image\n",
    "    n_c0 -- scalar, number of channels of the input\n",
    "    n_y -- scalar, number of classes\n",
    "        \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype \"float\"\n",
    "    y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n",
    "    \"\"\"\n",
    "\n",
    "    X_placeholder = tf.placeholder(tf.float32, [None, n_h0, n_w0, n_c0])\n",
    "    y_placeholder= tf.placeholder(tf.float32, [None, n_y])\n",
    "    \n",
    "    return X_placeholder, y_placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the placeholders \n",
    "\n",
    "To create the placeholders, you will need scalar inputs representing the shape of your inputs and outputs. To help with this, the annotation can defined as: \n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "$placeholder = tensor(height, width, channels, numclasses)$\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "You can access the heights, widths, channels, and number of classes by using the following: \n",
    "<br>\n",
    "```\n",
    "height = X.shape[1]\n",
    "width = X.shape[2]\n",
    "channels = X.shape[3]\n",
    "num_classes = y.shape[1]\n",
    "```\n",
    "<br>\n",
    "Let's try this out! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"Placeholder:0\", shape=(?, 256, 256, 3), dtype=float32)\n",
      "Y = Tensor(\"Placeholder_1:0\", shape=(?, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "################### Start Here ###################\n",
    "##################################################\n",
    "\n",
    "# Define the height of X\n",
    "n_h0 = X.shape[1]\n",
    "\n",
    "# Define the width of X\n",
    "n_w0 = X.shape[2]\n",
    "\n",
    "# Define the number of RGB channels \n",
    "n_c0 = X.shape[3]\n",
    "\n",
    "# Define the number of classes\n",
    "n_y  = y.shape[1]\n",
    "\n",
    "# Define the X and y placeholders\n",
    "X_ph, y_ph = create_placeholders(n_h0, n_w0, n_c0, n_y)\n",
    "\n",
    "# Print the place holders \n",
    "print (\"X = \" + str(X_ph))\n",
    "print (\"Y = \" + str(y_ph))\n",
    "\n",
    "\n",
    "##################################################\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layer \n",
    "\n",
    "Arguably the most important part of today is in understand what a convolutional layer is. Here is an example that we looked at in the presentation. \n",
    "\n",
    "<img src='conv_layer.jpg' align=right>\n",
    "<br><br>\n",
    "\n",
    "\n",
    "Fortunately for us, tensorflow makes it very easy to use convolutional layers. See this example for your code. \n",
    "\n",
    "```\n",
    "tf.nn.conv2d(input_data, weights, stride, padding='SAME')\n",
    "```\n",
    "<br>\n",
    "<br>\n",
    "If you have any questions during this part, now is the time to ask! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "################### Start Here ###################\n",
    "##################################################\n",
    "\n",
    "def convolutional_layer(input_data, \n",
    "                        num_channels, \n",
    "                        num_filters,\n",
    "                        filter_shape,\n",
    "                        name):\n",
    "    \"\"\" \n",
    "    Function used to prepare convolutional layers for image recognition training. \n",
    "    \n",
    "    Arguments: \n",
    "    input_date   : input vector (beginning with X input vector and then subsequent layer)\n",
    "    num_channels : the number of vectors corresponding to RGB values (=3)\n",
    "    num_filters  : the number of filters to apply to convolve the pixel arrays\n",
    "    filter_shape : the shape of the filters used to convolve the pixel arrays\n",
    "    pool_shape   : the shape and method for pooling\n",
    "    \n",
    "    Returns:\n",
    "    An Output Layer\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # FILL IN CODE HERE\n",
    "    # Define the filter shape for the convolutions (filter_shape x num_channels x num_filters)\n",
    "    conv_filter_shape = [filter_shape[0], filter_shape[1], num_channels, num_filters]\n",
    "    \n",
    "    \n",
    "    # FILL IN CODE HERE\n",
    "    # Initialize weights to assign to the filters \n",
    "    weights = tf.Variable(tf.truncated_normal(conv_filter_shape, stddev=0.03), name=name+'_W')\n",
    "    \n",
    "    # Defualt value\n",
    "    bias = tf.Variable(tf.truncated_normal([num_filters]), name=name+'_b')\n",
    "    \n",
    "    # Default value\n",
    "    stride = [1, 1, 1, 1]\n",
    "    \n",
    "    # FILL IN CODE HERE - if you have trouble, type ?tf.nn.conv2d for hints\n",
    "    # Setup the convolutional layer operation\n",
    "    output_layer = tf.nn.conv2d(input_data, weights, stride, padding='SAME')\n",
    "\n",
    "    \n",
    "    # Add the bias\n",
    "    output_layer += bias\n",
    "\n",
    "    \n",
    "    # Apply a ReLU non-linear activation\n",
    "    output_layer = tf.nn.relu(output_layer)\n",
    "    \n",
    "    return output_layer\n",
    "\n",
    "\n",
    "##################################################\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Pool Layer \n",
    "\n",
    "Fortunately, max pool is much easier to understand. \n",
    "\n",
    "<img src='maxpool.jpg' align=left>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "################### Start Here ###################\n",
    "##################################################\n",
    "\n",
    "def max_pool_layer(input_data, pool_shape):\n",
    "    \n",
    "    # Perform Max Pooling\n",
    "    ksize = [1, pool_shape[0], pool_shape[1], 1]\n",
    "    \n",
    "    strides = [1, 2, 2, 1]\n",
    "    \n",
    "    output_layer = tf.nn.max_pool(input_data, ksize=ksize, strides=strides, padding='SAME')\n",
    "    \n",
    "    return output_layer\n",
    "\n",
    "\n",
    "##################################################\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Computational Graph \n",
    "\n",
    "\n",
    "### What computation graph do we want? \n",
    "<br> \n",
    "\n",
    "We want to build our convolutional neural network architecture. We are going to use a very simple, 3-layer convolutional network which hopefully will work on our dataset. The model should look like this: \n",
    "\n",
    "<img src='architecture.jpg'>\n",
    "\n",
    "\n",
    "### Computational Graph\n",
    "When we define our convolutional and maxpool layers in the next step, what we are essentially doing is telling TensorFlow that this is the model we want to feed our data through. What is represented in the image is therefore interpreted as tensors in the computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the first convolution\n",
    "# Use 6 filters! \n",
    "conv_1 = convolutional_layer(X_ph, 3, 6, [3, 3], name='conv_1')\n",
    "\n",
    "# Define the first maxpool \n",
    "maxpool_1 = max_pool_layer(conv_1, [2, 2])\n",
    "\n",
    "# Define the first convolution\n",
    "# Use 12 filters! \n",
    "conv_2 = convolutional_layer(maxpool_1, 6, 12, [3, 3], name='conv2')\n",
    "\n",
    "# Define the second maxpool \n",
    "maxpool_2 = max_pool_layer(conv_2, [2, 2])\n",
    "\n",
    "# Define the third convolution\n",
    "# Use 6 filters \n",
    "conv_3 = convolutional_layer(maxpool_2, 12, 6, [3, 3], name='conv3')\n",
    "\n",
    "# Define the third maxpool \n",
    "maxpool_3 = max_pool_layer(conv_3, [2, 2])\n",
    "\n",
    "# Flatten the last maxpool layer \n",
    "flattened = tf.reshape(maxpool_3, [-1, 6144])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layers \n",
    "\n",
    "For the fully connected layers, don't worry too much about the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup some weights and bias values for this layer, then activate with ReLU\n",
    "fc_weights_1 = tf.Variable(tf.truncated_normal([6144, 200], stddev=0.03), name='fc_weights_1')\n",
    "fc_bias_1 = tf.Variable(tf.truncated_normal([200], stddev=0.01), name='fc_bias_1')\n",
    "fc_layer_1 = tf.matmul(flattened, fc_weights_1) + fc_bias_1\n",
    "fc_layer_1 = tf.nn.relu(fc_layer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# another layer with softmax activations\n",
    "fc_weights_2 = tf.Variable(tf.truncated_normal([200, 3], stddev=0.03), name='fc_weights_2')\n",
    "fc_bias_2 = tf.Variable(tf.truncated_normal([3], stddev=0.01), name='fc_bias_2')\n",
    "fc_layer_2 = tf.matmul(fc_layer_1, fc_weights_2) + fc_bias_2\n",
    "y_ = tf.nn.softmax(fc_layer_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Loss Measurement \n",
    "#### Note on Learning\n",
    "\n",
    "The way that neural networks learn is via something known as *gradient descent*. What this means is that after a forward pass through the network, the model goes **back**, and measures whether or not the weights and biases helped or hurt the overall loss score. It does so by using the *chain rule* (from high school calculus), and taking steps closer to the global minimum of the loss function. \n",
    "<br>\n",
    "\n",
    "<img src='gradient.jpg'>\n",
    "\n",
    "<br>\n",
    "For our case, we are going to define the $J()$ function (the loss function) as cross-entropy loss. Don't worry too much about this!  \n",
    "\n",
    "#### Note on Optimization \n",
    "2014 was a great year for deep learning. This guy from the University of Amsterdam discoverd the *de facto* optimisation algorithm, known as Adam. \n",
    "\n",
    "<br>\n",
    "<img src='adam.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function - J()\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=fc_layer_2, labels=y_ph))\n",
    "\n",
    "\n",
    "# Initiate an Adam Optimizer\n",
    "optimiser = tf.train.AdamOptimizer(learning_rate=.0003).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "# Define an accuracy score function (to print while we are training)\n",
    "correct_prediction = tf.equal(tf.argmax(y_ph, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model \n",
    "### Batch processing \n",
    "Because deep learning can be veryyyyyyy slow - sometime we need to split up our data in order to process it faster. This is known as minibatch processing, and works by essentially sending small amounts of data through the network, allow it to perform gradient descent (adjusting the weights), and then send the next batch. \n",
    "\n",
    "I like to think of this as a rapid-fire approach. Send through lots of little chunks of data so that we now how are model is doing. Once all of our batches are complete, we say that the model has completed an *epoch*\n",
    "\n",
    "### Initialize the Tensors!\n",
    "\n",
    "Tensorflow requires that we specify when we are intiializing the tensors defined above. We'll do this for you, but just a heads up. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a some batches from our training set \n",
    "batches = random_batch(X_train, y_train, batch_size=64)\n",
    "\n",
    "# Initialize tensors! \n",
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last, but not least\n",
    "\n",
    "Let's train this thing! I'm going to walk you through this part, so don't worry too much about the lack of hints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% |#########################################################               |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost = 0.894 test accuracy: 0.560\n",
      "Epoch: 2 cost = 0.809 test accuracy: 0.820\n",
      "Epoch: 3 cost = 0.756 test accuracy: 0.840\n",
      "Epoch: 4 cost = 0.614 test accuracy: 0.840\n",
      "Epoch: 5 cost = 0.480 test accuracy: 0.840\n",
      "Epoch: 6 cost = 0.402 test accuracy: 0.840\n",
      "Epoch: 7 cost = 0.367 test accuracy: 0.870\n",
      "Epoch: 8 cost = 0.342 test accuracy: 0.900\n",
      "Epoch: 9 cost = 0.342 test accuracy: 0.920\n",
      "Epoch: 10 cost = 0.420 test accuracy: 0.950\n",
      "Epoch: 11 cost = 0.420 test accuracy: 0.950\n",
      "Epoch: 12 cost = 0.189 test accuracy: 0.950\n",
      "Epoch: 13 cost = 0.182 test accuracy: 0.910\n",
      "Epoch: 14 cost = 0.176 test accuracy: 0.950\n",
      "Epoch: 15 cost = 0.136 test accuracy: 0.940\n",
      "Epoch: 16 cost = 0.117 test accuracy: 0.960\n",
      "Epoch: 17 cost = 0.086 test accuracy: 0.960\n",
      "Epoch: 18 cost = 0.066 test accuracy: 0.950\n",
      "Epoch: 19 cost = 0.047 test accuracy: 0.960\n",
      "Epoch: 20 cost = 0.035 test accuracy: 0.950\n",
      "Epoch: 21 cost = 0.028 test accuracy: 0.950\n",
      "Epoch: 22 cost = 0.023 test accuracy: 0.950\n",
      "Epoch: 23 cost = 0.020 test accuracy: 0.950\n",
      "Epoch: 24 cost = 0.018 test accuracy: 0.950\n",
      "Epoch: 25 cost = 0.016 test accuracy: 0.950\n",
      "Epoch: 26 cost = 0.014 test accuracy: 0.950\n",
      "Epoch: 27 cost = 0.013 test accuracy: 0.950\n",
      "Epoch: 28 cost = 0.012 test accuracy: 0.950\n",
      "Epoch: 29 cost = 0.011 test accuracy: 0.950\n",
      "Epoch: 30 cost = 0.010 test accuracy: 0.950\n",
      "Overall Test Accuracy 95.00%\n"
     ]
    }
   ],
   "source": [
    "# Initiate empty list to fill with costs \n",
    "costs = []\n",
    "\n",
    "# Initiate empty list to fill with accuracies \n",
    "accuracies = []\n",
    "\n",
    "# Initiate a progressbar \n",
    "bar = progressbar.ProgressBar(maxval=len(batches)).start()\n",
    "\n",
    "# Set a random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Begin a tensorflow session\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # (Actually) initialise the variables\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    \n",
    "    # START CODE HERE\n",
    "    # Define a for loop to iterate through 30 epochs\n",
    "    for epoch in range(30):\n",
    "        \n",
    "        # Iterate through each batch\n",
    "        for index, batch in enumerate(batches):\n",
    "            \n",
    "            # Define the input and outputs from the batch\n",
    "            X_batch, y_batch = batch\n",
    "            \n",
    "            # Initiate the average cost at 0\n",
    "            avg_cost = 0\n",
    "        \n",
    "            # Run an Adam optimizer and minimize the cross-entropy lost \n",
    "            # Don't forget to actually feed our data!\n",
    "            _, cost = sess.run([optimiser, cross_entropy], \n",
    "                                feed_dict={X_ph: X_batch, \n",
    "                                           y_ph: y_batch})\n",
    "            \n",
    "            \n",
    "            # Add the cost from the first batch\n",
    "            avg_cost += cost\n",
    "            costs.append(avg_cost)\n",
    "            \n",
    "            # Update the progressbar \n",
    "            bar.update(index)\n",
    "        \n",
    "        # Get he accuracy on the test set \n",
    "        test_accuracy = sess.run(accuracy, \n",
    "                                 feed_dict=\n",
    "                                 {X_ph: X_test, \n",
    "                                  y_ph: y_test})        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Append the accuracies list with the test accuracy \n",
    "        accuracies.append(test_accuracy)\n",
    "    \n",
    "        # Print out the information\n",
    "        print(\"Epoch:\", (epoch + 1), \"cost =\", \"{:.3f}\".format(avg_cost), \"test accuracy: {:.3f}\".format(test_accuracy))\n",
    "    \n",
    "    print(\"Overall Test Accuracy \" + \"%.2f\" % (sess.run(accuracy, feed_dict={X_ph: X_test, y_ph: y_test})*100) + '%')\n",
    "    \n",
    "    # In case we want to look at our predictions later \n",
    "    predictions = sess.run(y_, feed_dict={X_ph:X_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
